{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammatical_tasks = {\n",
    "    'gpt_sv_agreement': { # (new_col, correct_col, wrong_col). new_col is generally the shared prefix of the two cols\n",
    "        'simple': [('s', 'ss', 'sp'), ('p', 'pp', 'ps')], \n",
    "        'subjrelclause': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'sentcomp': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], # this one is a bit weird since the one that agrees is the second noun, order is second noun, first noun, verb\n",
    "        'shortvpcoord': [('ss', 'sss', 'ssp'), ('pp', 'ppp', 'pps')], # only taking case where first verb correctly agrees\n",
    "        'pp': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'objrelclausethat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'objrelclausenothat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "    }, \n",
    "    'gpt_anaphora': {\n",
    "        'simple': [('s', 'ss', 'sp'), ('p', 'pp', 'ps')], \n",
    "        'sentcomp': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], # this one is a bit weird since the one that agrees is the second noun and psp means second noun is p, first noun is s, anaphor is p\n",
    "        'objrelclausethat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'objrelclausenothat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "    }, \n",
    "    'bert_sv_agreement': { # (new_col, correct_col, wrong_col). new_col is generally the shared prefix of the two cols\n",
    "        'simple': [('s', 'ss', 'sp'), ('p', 'pp', 'ps')], \n",
    "        'subjrelclause': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'sentcomp': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], # this one is a bit weird since the one that agrees is the second noun, order is second noun, first noun, verb\n",
    "        'shortvpcoord': [('ss', 'sss', 'ssp'), ('pp', 'ppp', 'pps')], # only taking case where first verb correctly agrees\n",
    "        'pp': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'objrelclausethat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'objrelclausenothat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "    }, \n",
    "    'bert_anaphora': {\n",
    "        'simple': [('s', 'ss', 'sp'), ('p', 'pp', 'ps')], \n",
    "        'sentcomp': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], # this one is a bit weird since the one that agrees is the second noun and psp means second noun is p, first noun is s, anaphor is p\n",
    "        'objrelclausethat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'objrelclausenothat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "    }, \n",
    "    'txl_sv_agreement': { # (new_col, correct_col, wrong_col). new_col is generally the shared prefix of the two cols\n",
    "        'simple': [('s', 'ss', 'sp'), ('p', 'pp', 'ps')], \n",
    "        'subjrelclause': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'sentcomp': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], # this one is a bit weird since the one that agrees is the second noun, order is second noun, first noun, verb\n",
    "        'shortvpcoord': [('ss', 'sss', 'ssp'), ('pp', 'ppp', 'pps')], # only taking case where first verb correctly agrees\n",
    "        'pp': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'objrelclausethat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'objrelclausenothat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "    }, \n",
    "    'txl_anaphora': {\n",
    "        'simple': [('s', 'ss', 'sp'), ('p', 'pp', 'ps')], \n",
    "        'sentcomp': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], # this one is a bit weird since the one that agrees is the second noun and psp means second noun is p, first noun is s, anaphor is p\n",
    "        'objrelclausethat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "        'objrelclausenothat': [('ss', 'sss', 'ssp'), ('sp', 'sps', 'spp'), ('ps', 'psp', 'pss'), ('pp', 'ppp', 'pps')], \n",
    "    }, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the frequency counts\n",
    "freqs = {}\n",
    "with open(\"../sv_agreement/simple/word_freqs.json.txt\", \"r\") as f: \n",
    "    freqs = json.load(f)\n",
    "webtext_freqs = {}\n",
    "with open(\"../sv_agreement/simple/webtext_word_freqs.json.txt\", \"r\") as f: \n",
    "    webtext_freqs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_col(col, fine_tuned=False): \n",
    "    col_name_split = ['SG' if c=='s' else 'PL' for c in col]\n",
    "    if fine_tuned: \n",
    "        col_name_split.pop(0)\n",
    "    return '_'.join(col_name_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_column_differences(df, sent_type, task, fine_tuned_number=None): \n",
    "    fine_tuned = fine_tuned_number is not None\n",
    "    if fine_tuned: \n",
    "        fine_tuned_number = fine_tuned_number.lower()\n",
    "        if fine_tuned_number not in ['sg', 'pl']: \n",
    "            raise ValueError('fine_tuned_number in take_column_differences is wrong: ' + str(fine_tuned_number))\n",
    "    new_df = pd.DataFrame()\n",
    "    for new_col, correct_col, wrong_col in grammatical_tasks[sent_type][task]: \n",
    "        correct_col_name = convert_to_col(correct_col, fine_tuned=fine_tuned)\n",
    "        wrong_col_name = convert_to_col(wrong_col, fine_tuned=fine_tuned)\n",
    "        if fine_tuned: \n",
    "            if new_col[0] != fine_tuned_number[0]: \n",
    "                continue\n",
    "        new_df[new_col] = df[correct_col_name]-df[wrong_col_name]\n",
    "    if fine_tuned: \n",
    "        new_df['category'] = df['category']\n",
    "        new_df['model_name'] = df['model_name']\n",
    "    else: \n",
    "        new_df['sent'] = df['sent']\n",
    "        if sent_type.startswith('gpt'): \n",
    "            new_df['s_freq'] = [webtext_freqs[x][2] for x in df['sent']]\n",
    "            new_df['p_freq'] = [webtext_freqs[x][3] for x in df['sent']]\n",
    "            new_df['freq'] = [webtext_freqs[x][4] for x in df['sent']]\n",
    "        else: \n",
    "            new_df['s_freq'] = [freqs[x][2] for x in df['sent']]\n",
    "            new_df['p_freq'] = [freqs[x][3] for x in df['sent']]\n",
    "            new_df['freq'] = [freqs[x][4] for x in df['sent']]\n",
    "    new_df = new_df[(new_df.T != 0).all()]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    's': 'r', \n",
    "    'p': 'b', \n",
    "    'ss': 'r', \n",
    "    'sp': 'b', \n",
    "    'ps': 'c', \n",
    "    'pp': 'm',\n",
    "}\n",
    "\n",
    "not_plot_cols = {'freq', 'sent', 's_freq', 'p_freq'}\n",
    "\n",
    "def plot_task(df, sent_type, task, sg_df=None, pl_df=None): \n",
    "    plot_one_shots = sg_df is not None\n",
    "    to_graphs = [[col_name] for col_name in df.columns if col_name not in not_plot_cols]\n",
    "    if not plot_one_shots: \n",
    "        to_graphs.append([col_name for col_name in df.columns if col_name not in not_plot_cols])\n",
    "    for to_graph in to_graphs: \n",
    "        fig = plt.figure(figsize=(12.8,9.6))\n",
    "        ax = plt.gca()\n",
    "        ax.set_xscale('log')\n",
    "        plt.ylabel(\"Mean of diffs\")\n",
    "        plt.xlabel(\"Frequency of noun in wikitext-103 training set\")\n",
    "        plt.xlim(1, 10e5)\n",
    "        plt.title(\"%s: Freq. of nouns vs mean of dist. of diffs (correct-wrong) (%s)\" % (sent_type, task))\n",
    "        for struct in to_graph: \n",
    "            x = df[f'{struct[0]}_freq']\n",
    "            y = df[struct]\n",
    "\n",
    "            ax.scatter(x, y, label=struct, s=2, color=colors[struct])\n",
    "        if plot_one_shots and len(to_graph)==1: \n",
    "            colormap = plt.cm.gist_ncar\n",
    "            if to_graph[0][0] == 's': \n",
    "                sub_df = sg_df\n",
    "            else: # 'p'\n",
    "                sub_df = pl_df\n",
    "            colorcycle = [colormap(i) for i in np.linspace(0, 0.9, len(sub_df)+1)]\n",
    "            for index, row in sub_df.iterrows(): \n",
    "                ax.axhline(row[to_graph[0]], label=row['model_name'], c=colorcycle[index], lw=1)\n",
    "            ax.axhline(df[to_graph[0]].mean(), label='base_mean', c=colorcycle[len(sub_df)], lw=1)\n",
    "\n",
    "            plt.legend()\n",
    "\n",
    "            filename = '../one_shot/figures/%s/%s/finetune_%s-%s.png' % (sent_type, task, task, '_'.join(to_graph))\n",
    "\n",
    "            filename_split = filename[3:].split('/')[:-1] # [2:] to get rid of ../, [:-1] because don't want the png filename\n",
    "            for i in range(1, len(filename_split)+1): \n",
    "                subdir = '/'.join(filename_split[:i])\n",
    "                if not os.path.isdir(subdir): \n",
    "                    os.mkdir(subdir)\n",
    "\n",
    "            plt.savefig(filename)\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "        plt.legend()\n",
    "        \n",
    "        filename = '../%s/figures/%s/freqs_%s-%s.png' % (sent_type, task, task, '_'.join(to_graph))\n",
    "\n",
    "        # make directories if needed\n",
    "\n",
    "        filename_split = filename.split('/')[:-1] # [2:] to get rid of ./, [:-1] because don't want the png filename\n",
    "        for i in range(1, len(filename_split)+1): \n",
    "            subdir = '/'.join(filename_split[:i])\n",
    "            if not os.path.isdir(subdir): \n",
    "                os.mkdir(subdir)\n",
    "                print('making %s' % subdir)\n",
    "\n",
    "        plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_plotting_pipeline(retake_differences = False, save_differences = False, specific_task=None, one_shot=False):  \n",
    "    \"\"\"\n",
    "    set retake_differences to true to always compute differences (do this if changing which differences to take)\n",
    "    \"\"\"\n",
    "    def run_task(sent_type, task, one_shot=False): \n",
    "        differences_filename = '../%s/differences_data/%s.differences.csv' % (sent_type, task)\n",
    "        if not retake_differences and os.path.exists(differences_filename): \n",
    "            df = pd.read_csv(differences_filename)\n",
    "        else: \n",
    "            df = pd.read_csv('../%s/consolidated_data/%s.consolidated.csv' % (sent_type, task))\n",
    "            df = take_column_differences(df, sent_type, task)\n",
    "            if save_differences: \n",
    "                df.to_csv(differences_filename, index=False)\n",
    "            \n",
    "        if one_shot: \n",
    "            split_ind = sent_type.index('_')\n",
    "            model = sent_type[:split_ind]\n",
    "            sent_type_short = sent_type[split_ind+1:]\n",
    "            sg_df = pd.read_csv('../compute/one_shot_consolidated_results/%s/sg/%s/%s.csv' % (model, sent_type_short, task))\n",
    "            pl_df = pd.read_csv('../compute/one_shot_consolidated_results/%s/pl/%s/%s.csv' % (model, sent_type_short, task))\n",
    "            sg_df = take_column_differences(sg_df, sent_type, task, fine_tuned_number='sg')\n",
    "            pl_df = take_column_differences(pl_df, sent_type, task, fine_tuned_number='pl')\n",
    "            # can't merge because trained with different things\n",
    "            # one_shot_df = sg_df.merge(pl_df, on=['category', 'model_name'])\n",
    "            # one_shot_df = one_shot_df[[c for c in one_shot_df if c!='category' and c!='model_name']+['category', 'model_name']] \n",
    "            plot_task(df, sent_type, task, sg_df=sg_df, pl_df=pl_df)\n",
    "        else: \n",
    "            plot_task(df, sent_type, task)\n",
    "\n",
    "    if specific_task is not None: \n",
    "        run_task(*specific_task, one_shot=one_shot)\n",
    "    else: \n",
    "        for sent_type in grammatical_tasks: \n",
    "            for task in grammatical_tasks[sent_type]: \n",
    "                run_task(sent_type, task, one_shot=one_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_plotting_pipeline(retake_differences=True, save_differences=True)\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}